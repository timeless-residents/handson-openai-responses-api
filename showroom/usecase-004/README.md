# ユースケース 004: パラメータ調整（temperature, top_p, max_output_tokens）

このユースケースでは、OpenAI Responses APIの出力制御パラメータを使用して、モデルの応答の創造性、多様性、長さをコントロールする方法を紹介します。

## 概要

Responses APIでは、さまざまなパラメータを調整することで、同じプロンプトに対しても異なる特性を持つ応答を生成できます。このサンプルでは、以下の主要なパラメータに焦点を当てています：

1. **temperature**: 出力の多様性と創造性を制御します（0.0～2.0）
2. **top_p**: 確率の高いトークン選択を制御するnucleusサンプリングパラメータ（0.0～1.0）
3. **max_output_tokens**: 生成される応答の最大トークン数を制限します（最小値16）

このサンプルでは、以下の実験を通じてこれらのパラメータの効果を示します：

1. **temperatureの比較**: 異なるtemperature値（0.0, 0.5, 1.0, 1.5）での応答の違い
2. **top_pの比較**: 異なるtop_p値（0.1, 0.5, 0.9, 1.0）での応答の違い
3. **max_output_tokensの比較**: 異なるトークン数制限（16, 30, 100, 300）での応答の違い
4. **パラメータの組み合わせ**: 実用的なシナリオに基づいた複数パラメータの組み合わせ例

## 実行方法

1. プロジェクトのルートディレクトリに`.env`ファイルを作成し、OpenAI APIキーを設定します：

```
OPENAI_API_KEY=your_api_key_here
```

2. 必要なパッケージをインストールします：

```bash
pip install -r requirements.txt
```

3. スクリプトを実行します：

```bash
python main.py
```

## パラメータの詳細

### temperature

- **範囲**: 0.0～2.0（デフォルト: 1.0）
- **効果**: 出力の多様性と創造性を制御
- **低い値（0.0～0.5）**: より決定論的で予測可能な応答
- **中間の値（0.6～1.2）**: バランスの取れた創造性
- **高い値（1.3～2.0）**: より予測不可能で創造的な応答
- **ユースケース**: 事実ベースの情報（低）、創造的なコンテンツ生成（高）

### top_p（nucleus sampling）

- **範囲**: 0.0～1.0（デフォルト: 1.0）
- **効果**: トークン選択の確率分布を制御
- **low（0.1）**: 最も確率の高いトークンのみを考慮
- **high（1.0）**: より広い範囲のトークンを考慮
- **注意**: temperatureとtop_pは同時に調整せず、どちらか一方を使用するのが推奨
- **ユースケース**: 多様性と一貫性のバランスが必要な応用に適する

### max_output_tokens

- **範囲**: 16以上（APIの制限による最小値）
- **効果**: 生成される応答の最大トークン数を制限
- **ユースケース**:
  - 短い要約や簡潔な回答の生成
  - APIコストの管理
  - 一貫した長さの応答の確保
  - 冗長な応答の防止

## 実用的なパラメータ設定例

このサンプルでは、以下のような実用的なパラメータ設定の例も示しています：

1. **創造的な詩の生成**:
   - temperature: 1.5（高い創造性）
   - max_output_tokens: 150（適度な長さ）
   - instructions: 創造的な詩人としての役割を指定

2. **事実に基づく説明**:
   - temperature: 0.2（低い創造性、高い一貫性）
   - max_output_tokens: 200（適度な長さ制限）
   - instructions: 科学教師としての正確な説明を要求

3. **特定フォーマットの出力**:
   - temperature: 0.7（中程度の創造性）
   - top_p: 0.8（控えめな多様性）
   - instructions: 特定のフォーマットを指定

## パラメータ選択のガイドライン

| 用途 | temperature | top_p | max_output_tokens | その他 |
|------|-------------|-------|-------------------|--------|
| 事実説明 | 0.0～0.3 | 0.9～1.0 | アプリに応じて設定（≥16） | instructions: 正確さを強調 |
| QA | 0.2～0.5 | 0.9～1.0 | 短めに設定（≥16） | 簡潔な回答を要求 |
| 要約 | 0.3～0.6 | 0.9～1.0 | 元のコンテンツの1/3程度 | 重要ポイントに焦点 |
| コンテンツ生成 | 0.7～1.2 | 0.8～1.0 | 目的に応じて | 創造性の程度を調整 |
| ブレインストーミング | 1.0～2.0 | 0.9～1.0 | 制限なし/高め | 多様なアイデア生成 |
| 物語・詩 | 0.8～1.5 | 0.8～1.0 | ジャンルに応じて | スタイル指定も効果的 |

## 応用例

1. **カスタマーサポート**: 低temperatureで正確な情報提供
2. **コンテンツマーケティング**: 中程度のtemperatureで創造的かつ関連性の高いコンテンツ
3. **教育コンテンツ**: 制限されたmax_output_tokensで簡潔な説明
4. **クリエイティブライティング**: 高temperatureで独創的なアイデア
5. **データ要約**: 低temperatureと制限されたmax_output_tokensで重要ポイントを抽出

## 注意点

- temperatureとtop_pは同時に調整せず、どちらか一方のみを変更するのが推奨されています
- パラメータの最適な組み合わせはユースケースによって異なります
- 実験を通じて特定のアプリケーションに最適な設定を見つけることをお勧めします
- max_output_tokensの最小値は16です（OpenAI APIの制限）

## 参考資料

- [OpenAI Responses API ドキュメント](https://platform.openai.com/docs/api-reference/responses)
- [OpenAI のパラメータ設定ガイド](https://platform.openai.com/docs/guides/text-generation)