# ユースケース 003: ストリーミングによるリアルタイム応答表示

このユースケースでは、OpenAI Responses APIのストリーミング機能を使用して、モデルの応答をリアルタイムで取得し表示する方法を紹介します。

## 概要

ストリーミングは、モデルが応答を生成するのと同時に、その内容を小さな断片（チャンク）として受け取る機能です。この機能を使用することで：

- ユーザーはモデルの思考プロセスをリアルタイムで見ることができる
- 応答の生成に時間がかかる場合でも、ユーザー体験を向上できる
- 生成中の内容に基づいて早期に処理を開始できる
- 生成イベントの詳細な制御とモニタリングが可能

このサンプルでは、以下の3つのデモンストレーションを行います：

1. **短い質問への回答**: 基本的なストリーミングの例
2. **創造的なコンテンツ生成**: システムプロンプトを併用した、より長い創造的な内容の生成
3. **段階的な説明**: 構造化された長いレスポンスの生成と表示

## 実行方法

1. プロジェクトのルートディレクトリに`.env`ファイルを作成し、OpenAI APIキーを設定します：

```
OPENAI_API_KEY=your_api_key_here
```

2. 必要なパッケージをインストールします：

```bash
pip install -r requirements.txt
```

3. スクリプトを実行します：

```bash
python main.py
```

## ストリーミングの仕組み

Responses APIでストリーミングを使用するには、リクエスト時に`stream=True`パラメータを設定します：

```python
response = client.responses.create(
    model="gpt-4o",
    input="質問やプロンプト",
    stream=True
)
```

応答はイベントストリームとして返され、以下のようなイベントタイプが含まれます：

- `response.created`: レスポンスが作成された
- `response.in_progress`: レスポンスの生成が進行中
- `response.output_item.added`: 新しい出力アイテムが追加された
- `response.content_part.added`: 新しいコンテンツパートが追加された
- `response.output_text.delta`: テキスト出力に増分が追加された
- `response.output_text.done`: テキスト出力が完了した
- `response.output_item.done`: 出力アイテムが完了した
- `response.completed`: レスポンス全体が完了した

## サンプルコードの解説

`main.py`は以下の主要な機能で構成されています：

1. **環境設定**: APIキーの取得とクライアント初期化
2. **ストリーミングレスポンス生成**: `stream=True`オプションを使用してAPI呼び出し
3. **イベント処理**: 各種ストリーミングイベントの処理と表示
4. **3つのデモンストレーション**: 異なるタイプの内容生成を示す例

## 実装上の注意点

- ストリーミングイベントの種類によって処理を分けることが重要です
- `response.output_text.delta`イベントには増分テキストが含まれます
- イベントの順序は予測可能ですが、処理速度によって変わる場合があります
- 最終的な応答内容は、個々のデルタを結合することで取得できます

## 応用例

ストリーミングAPIは以下のようなアプリケーションに特に適しています：

1. **チャットインターフェース**: 人間らしい対話体験を提供
2. **ライブコンテンツ生成**: 記事、物語、詩などのリアルタイム生成
3. **教育アプリケーション**: 段階的な説明や考え方の展開を示す
4. **コーディングアシスタント**: コードの生成過程を示す
5. **翻訳ツール**: リアルタイムで翻訳結果を表示

## パフォーマンスとコスト

ストリーミングを使用しても、APIの使用コストは変わりません。同じトークン数に対して課金されますが、ユーザー体験が大幅に向上します。また、ネットワーク接続の品質に依存するため、安定した接続が重要です。

## その他の機能との併用

ストリーミングは他のResponses API機能と併用できます：

- システムプロンプト（instructions）
- 複数入力テキスト
- 構造化出力
- 会話状態管理

## 参考資料

- [OpenAI Responses API ストリーミングドキュメント](https://platform.openai.com/docs/api-reference/responses)
- [ストリーミングイベントの種類](https://platform.openai.com/docs/api-reference/responses/streaming)